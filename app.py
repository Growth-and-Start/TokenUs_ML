from flask import Flask, request, jsonify
import os
import requests
import boto3
from dotenv import load_dotenv
import cv2
import torch
import torchvision.transforms as transforms
from torchvision.models import resnet50
import faiss
import numpy as np

app = Flask(__name__)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(".env")

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
AWS_ACCESS_KEY_ID = os.getenv("AWS_ACCESS_KEY_ID")
AWS_SECRET_ACCESS_KEY = os.getenv("AWS_SECRET_ACCESS_KEY")
AWS_REGION = os.getenv("AWS_REGION")
S3_BUCKET_NAME = os.getenv("S3_BUCKET_NAME")

if not all([AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_REGION, S3_BUCKET_NAME]):
    raise ValueError("í™˜ê²½ ë³€ìˆ˜ê°€ ì œëŒ€ë¡œ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")


# S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±
s3_client = boto3.client(
    "s3",
    aws_access_key_id=AWS_ACCESS_KEY_ID,
    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
    region_name=AWS_REGION
)

# ë‹¤ìš´ë¡œë“œëœ ì˜ìƒì„ ì €ì¥í•  í´ë” ìƒì„±
DOWNLOAD_FOLDER = "downloads"
os.makedirs(DOWNLOAD_FOLDER, exist_ok=True)

def delete_s3_file(s3_url):
    """
    S3ì— ì—…ë¡œë“œëœ ì˜ìƒì„ ì‚­ì œí•˜ëŠ” í•¨ìˆ˜
    """
    try:
        # S3 URLì—ì„œ ë²„í‚·ëª…ê³¼ íŒŒì¼ í‚¤ ì¶”ì¶œ
        bucket_name = "tokenus-storage"  # âœ… S3 ë²„í‚·ëª…
        key = s3_url.replace(f"https://{bucket_name}.s3.ap-northeast-2.amazonaws.com/", "")

        # S3 ê°ì²´ ì‚­ì œ
        s3_client.delete_object(Bucket=bucket_name, Key=key)
        print(f"âœ… S3ì—ì„œ íŒŒì¼ ì‚­ì œ ì„±ê³µ: {s3_url}")

    except Exception as e:
        print(f"âŒ S3ì—ì„œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {s3_url}, ì˜¤ë¥˜: {e}")

@app.route("/download", methods=['POST'])
def download_video():
    data = request.json
    video_url = data.get('file_url')
    
    if not video_url:
        return jsonify({"error": "No video_url provided"}), 400
    
    # S3 ê°ì²´ í‚¤(íŒŒì¼ ê²½ë¡œ) ì¶”ì¶œ
    object_key = video_url.split(".com/")[-1]  # "videos/test3.mov"
    
    try:
        # ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ ê²½ë¡œ ì„¤ì •
        filename = object_key.split("/")[-1]
        file_path = os.path.join(DOWNLOAD_FOLDER, filename)
        
        # S3ì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        s3_client.download_file(S3_BUCKET_NAME, object_key, file_path)
        
        #return jsonify({"message": "Download successful", "file_path": file_path})
        
        # âœ… ìë™ìœ¼ë¡œ check_similarity ìˆ˜í–‰
        similarity_result = perform_similarity_check(file_path)

        return jsonify({
            "message": "Download successful",
            "file_path": file_path,
            "similarity_check_result": similarity_result
        })
        
    except Exception as e:
        return jsonify({"error": str(e)}), 500

def perform_similarity_check(video_path):
    """
    ì €ì¥ëœ ëª¨ë“  ë²¡í„°ì™€ ì…ë ¥ëœ ì˜ìƒì˜ ë²¡í„° ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë¹„êµ.
    ê°™ì€ ì˜ìƒì¸ì§€ íŒë‹¨í•˜ëŠ” ê¸°ì¤€:
    - í•œ ê°œ ì´ìƒì˜ ë²¡í„°ê°€ 0.8 ì´ìƒ
    - í‰ê·  ìœ ì‚¬ë„ê°€ 0.75 ì´ìƒ
    """
    if not video_path or not os.path.exists(video_path):
        return {"error": "Invalid video path"}

    try:
        # 1ï¸âƒ£ FAISS ì¸ë±ìŠ¤ ë¡œë“œ
        load_faiss_index()

        # 2ï¸âƒ£ ì €ì¥ëœ ë²¡í„° ê°œìˆ˜ í™•ì¸
        total_vectors = faiss_index.index.ntotal
        if total_vectors == 0:
            similarity_result = {
                "message": "ìœ ì‚¬ë„ ê²€ì‚¬ë¥¼ í†µê³¼í•˜ì˜€ìŠµë‹ˆë‹¤",
                "max_similarity": 0,
                "avg_similarity": 0
            }
            notify_springboot(video_path, similarity_result, passed=True)
            return similarity_result
            

        # 3ï¸âƒ£ ë¹„êµí•  ì˜ìƒì—ì„œ í”„ë ˆì„ ì¶”ì¶œ
        frames = extract_frames(video_path)

        # 4ï¸âƒ£ í”„ë ˆì„ì˜ íŠ¹ì§• ë²¡í„° ì¶”ì¶œ
        feature_vectors = extract_features(frames)

        # 5ï¸âƒ£ ë²¡í„° ì •ê·œí™” (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ë¹„êµ)
        query_vectors = np.array(feature_vectors).astype('float32')
        faiss.normalize_L2(query_vectors)

        # 6ï¸âƒ£ ê° í”„ë ˆì„ì˜ ë²¡í„°ë¥¼ FAISSì— ì €ì¥ëœ ëª¨ë“  ë²¡í„°ì™€ ë¹„êµ
        similarity_scores = []
        for query_vector in query_vectors:
            query_vector = query_vector.reshape(1, -1)
            faiss.normalize_L2(query_vector)  # âœ… ê²€ìƒ‰ ë²¡í„° ì •ê·œí™”
            distances, _ = faiss_index.index.search(query_vector, total_vectors)
            similarity_scores.extend(distances[0].tolist())

        # 7ï¸âƒ£ ê²€ì‚¬ ê¸°ì¤€ ì ìš©
        max_similarity = max(similarity_scores)
        avg_similarity = sum(similarity_scores) / len(similarity_scores)

        similarity_result = {
            "max_similarity": max_similarity,
            "avg_similarity": avg_similarity
        }

        if max_similarity >= 1.0 or (max_similarity >= 0.9 and avg_similarity >= 0.8):
            similarity_result["message"] = "ìœ ì‚¬ë„ ê²€ì‚¬ë¥¼ ì‹¤íŒ¨í•˜ì˜€ìŠµë‹ˆë‹¤"
            # âŒ ë¡œì»¬ íŒŒì¼ ì‚­ì œ
            delete_file(video_path)

            # âŒ S3ì—ì„œë„ ì‚­ì œ
            delete_s3_file(video_path)

            # âŒ Spring Boot ì„œë²„ì— ìœ ì‚¬ë„ ê²€ì‚¬ ì‹¤íŒ¨ ì•Œë¦¼
            notify_springboot(video_path, similarity_result, passed=False)
            return similarity_result
        else:
            similarity_result["message"] = "ìœ ì‚¬ë„ ê²€ì‚¬ë¥¼ í†µê³¼í•˜ì˜€ìŠµë‹ˆë‹¤"
            # âœ… FAISSì— ë²¡í„° ì €ì¥
            faiss_index.add_vectors(feature_vectors)
            save_faiss_index()  # ì €ì¥ëœ FAISS ì¸ë±ìŠ¤ íŒŒì¼ ì—…ë°ì´íŠ¸

            # âŒ ë¡œì»¬ íŒŒì¼ ì‚­ì œ
            delete_file(video_path)

            # âœ… Spring Boot ì„œë²„ì— ìœ ì‚¬ë„ ê²€ì‚¬ ì„±ê³µ ì•Œë¦¼
            notify_springboot(video_path, similarity_result, passed=True)
            
            return similarity_result

    except Exception as e:
        return {"error": str(e)}

def delete_file(file_path):
    """ë¡œì»¬ì— ì €ì¥ëœ ì˜ìƒ íŒŒì¼ ì‚­ì œ"""
    try:
        if os.path.exists(file_path):
            os.remove(file_path)
            print(f"ğŸ—‘ íŒŒì¼ ì‚­ì œ ì™„ë£Œ: {file_path}")
    except Exception as e:
        print(f"ğŸš¨ íŒŒì¼ ì‚­ì œ ì˜¤ë¥˜: {e}")
        
        
SPRINGBOOT_URL = "http://127.0.0.1:8080/video/similarity-check"  # Spring Boot ì„œë²„ URL

def notify_springboot(video_path, similarity_result, passed):
    """
    Spring Boot ì„œë²„ì— ìœ ì‚¬ë„ ê²€ì‚¬ ê²°ê³¼ ì „ì†¡
    :param video_path: ê²€ì‚¬í•œ ì˜ìƒ ê²½ë¡œ
    :param similarity_result: ìœ ì‚¬ë„ ê²€ì‚¬ ê²°ê³¼
    :param passed: ìœ ì‚¬ë„ ê²€ì‚¬ë¥¼ í†µê³¼í–ˆëŠ”ì§€ ì—¬ë¶€ (True: í†µê³¼, False: ì‹¤íŒ¨)
    """
    payload = {
        "video_path": video_path,
        "max_similarity": similarity_result["max_similarity"],
        "avg_similarity": similarity_result["avg_similarity"],
        "message": similarity_result["message"],
        "passed": passed  # âœ… í†µê³¼ ì—¬ë¶€ ì¶”ê°€
    }

    try:
        print("payload:",payload)
        headers = {'Content-Type': 'application/json'}
        response = requests.post(SPRINGBOOT_URL, json=payload, headers=headers)
        print(f"ğŸ“¡ Spring Boot ì‘ë‹µ: {response.status_code} - {response.text}")
    except requests.exceptions.RequestException as e:
        print(f"ğŸš¨ Spring Boot ì „ì†¡ ì˜¤ë¥˜: {e}")


#ì˜ìƒ í”„ë ˆì„ ì¶”ì¶œ
def extract_frames(video_path, interval=1):
    """
    ì£¼ì–´ì§„ ì˜ìƒì—ì„œ ì¼ì • ê°„ê²©ë§ˆë‹¤ í”„ë ˆì„ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
    :param video_path: ì˜ìƒ íŒŒì¼ ê²½ë¡œ
    :param interval: ì´ˆ ë‹¨ìœ„ ê°„ê²© (1ì´ˆë§ˆë‹¤ í”„ë ˆì„ ì¶”ì¶œ)
    :return: í”„ë ˆì„ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
    """
    cap = cv2.VideoCapture(video_path)
    
    if not cap.isOpened():
        raise ValueError("Error: Unable to open video file.")
    
    fps = int(cap.get(cv2.CAP_PROP_FPS))  # ì´ˆë‹¹ í”„ë ˆì„ ìˆ˜
    frame_interval = fps * interval  # ê°„ê²© ì„¤ì •
    
    frames = []
    frame_count = 0
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break  # ì˜ìƒ ì¢…ë£Œ ì‹œ ë°˜ë³µ ì¤‘ì§€

        if frame_count % frame_interval == 0:
            frames.append(frame)

        frame_count += 1

    cap.release()
    return frames
    

# ResNet-50 ëª¨ë¸ ë¡œë“œ
resnet = resnet50(pretrained=True)
resnet = torch.nn.Sequential(*list(resnet.children())[:-1])  # ë§ˆì§€ë§‰ FC ë ˆì´ì–´ ì œê±°
resnet.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë³€í™˜ ì •ì˜
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

def extract_features(frames):
    """
    ResNet-50ì„ ì‚¬ìš©í•´ ì£¼ì–´ì§„ í”„ë ˆì„ ë¦¬ìŠ¤íŠ¸ì—ì„œ íŠ¹ì§• ë²¡í„°ë¥¼ ì¶”ì¶œ
    :param frames: ì˜ìƒ í”„ë ˆì„ ë¦¬ìŠ¤íŠ¸
    :return: íŠ¹ì§• ë²¡í„° ë¦¬ìŠ¤íŠ¸ (2048ì°¨ì›)
    """
    features = []
    with torch.no_grad():  # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™”
        for frame in frames:
            img_tensor = transform(frame).unsqueeze(0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
            feature_vector = resnet(img_tensor)  # (1, 2048, 1, 1) í˜•íƒœ ì¶œë ¥
            feature_vector = feature_vector.view(-1).numpy()  # 1D ë²¡í„°ë¡œ ë³€í™˜
            features.append(feature_vector)

    return features
    

class FAISSIndex:
    def __init__(self, dim=2048):
        """
        FAISSë¥¼ ì‚¬ìš©í•´ íŠ¹ì§• ë²¡í„°ë¥¼ ì €ì¥í•˜ëŠ” í´ë˜ìŠ¤
        :param dim: ë²¡í„° ì°¨ì› (ResNet-50ì€ 2048)
        """
        # self.index = faiss.IndexFlatL2(dim)  # L2 ê±°ë¦¬ ê¸°ë°˜ ì¸ë±ìŠ¤ ìƒì„±
        self.index = faiss.IndexFlatIP(dim) # ë‚´ì  ê¸°ë°˜ ì¸ë±ìŠ¤(ì½”ì‚¬ì¸ ìœ ì‚¬ë„ì— ì í•©)

    def add_vectors(self, vectors):
        """
        ë²¡í„° ì¶”ê°€
        :param vectors: íŠ¹ì§• ë²¡í„° ë¦¬ìŠ¤íŠ¸ (numpy array)
        """
        vectors = np.array(vectors).astype('float32')
        faiss.normalize_L2(vectors) # ë²¡í„° ì •ê·œí™”
        self.index.add(vectors)

    def search(self, query_vector, top_k=5):
        """
        ê°€ì¥ ìœ ì‚¬í•œ ë²¡í„° ê²€ìƒ‰
        :param query_vector: ê²€ìƒ‰í•  ë²¡í„° (2048ì°¨ì›)
        :param top_k: ìƒìœ„ Kê°œ ê²€ìƒ‰
        :return: ìœ ì‚¬í•œ ë²¡í„° ì¸ë±ìŠ¤ì™€ ê±°ë¦¬
        """
        query_vector = np.array(query_vector).astype('float32').reshape(1, -1)
        faiss.normalize_L2(query_vector) # ì •ê·œí™”
        distances, indices = self.index.search(query_vector, top_k)
        return indices, distances
    

def convert_faiss_to_cosine():
    """L2 ê±°ë¦¬ ê¸°ë°˜ FAISSë¥¼ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ ë³€í™˜"""
    global faiss_index

    total_vectors = faiss_index.index.ntotal
    if total_vectors == 0:
        print("ğŸ“¢ FAISSì— ì €ì¥ëœ ë²¡í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë³€í™˜í•  í•„ìš” ì—†ìŒ.")
        return

    print(f"ğŸ”„ ê¸°ì¡´ L2 ê¸°ë°˜ ë²¡í„° {total_vectors}ê°œ ë³€í™˜ ì¤‘...")

    # ê¸°ì¡´ ë²¡í„° ê°€ì ¸ì˜¤ê¸°
    stored_vectors = np.zeros((total_vectors, 2048), dtype=np.float32)
    for i in range(total_vectors):
        stored_vectors[i] = faiss_index.index.reconstruct(i)

    # ë²¡í„° ì •ê·œí™” (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°ì„ ìœ„í•´)
    faiss.normalize_L2(stored_vectors)

    # ìƒˆë¡œìš´ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ FAISS ì¸ë±ìŠ¤ ìƒì„± (IndexFlatIP ì‚¬ìš©)
    new_index = faiss.IndexFlatIP(2048)
    new_index.add(stored_vectors)  # ì •ê·œí™”ëœ ë²¡í„° ì¶”ê°€

    # ê¸°ì¡´ FAISS ì¸ë±ìŠ¤ë¥¼ ìƒˆë¡œìš´ ì¸ë±ìŠ¤ë¡œ êµì²´
    faiss_index.index = new_index

    # ë³€í™˜ëœ FAISS ì¸ë±ìŠ¤ë¥¼ ì €ì¥
    save_faiss_index()

    print("âœ… L2 â†’ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë³€í™˜ ì™„ë£Œ ë° ì €ì¥ë¨!")

 
FAISS_INDEX_PATH = "faiss_index.bin"

def save_faiss_index():
    """FAISS ì¸ë±ìŠ¤ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    faiss.write_index(faiss_index.index, FAISS_INDEX_PATH)

def load_faiss_index():
    """FAISS ì¸ë±ìŠ¤ë¥¼ íŒŒì¼ì—ì„œ ë¶ˆëŸ¬ì˜¤ê¸°"""
    global faiss_index
    if os.path.exists(FAISS_INDEX_PATH):
        print("ğŸ”„ FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ!")
        index = faiss.read_index(FAISS_INDEX_PATH)
        faiss_index.index = index  # ê¸°ì¡´ ê°ì²´ë¥¼ ë®ì–´ì”Œìš°ì§€ ì•Šê³  ìœ ì§€

# FAISS ì¸ë±ìŠ¤ ì „ì—­ ë³€ìˆ˜ë¡œ ìƒì„±
faiss_index = FAISSIndex(dim=2048)

# ì„œë²„ ì‹œì‘ ì‹œ FAISS ì¸ë±ìŠ¤ ë¡œë“œ
load_faiss_index()
convert_faiss_to_cosine()  # âœ… ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë³€í™˜

@app.route('/process_video', methods=['POST'])
def process_video():
    data = request.json
    video_path = data.get("video_path")  # ë‹¤ìš´ë¡œë“œëœ ì˜ìƒ ê²½ë¡œ

    if not video_path or not os.path.exists(video_path):
        return jsonify({"error": "Invalid video path"}), 400

    try:
        # 1ï¸âƒ£ ì˜ìƒì—ì„œ í”„ë ˆì„ ì¶”ì¶œ
        frames = extract_frames(video_path)

        # 2ï¸âƒ£ í”„ë ˆì„ì—ì„œ íŠ¹ì§• ë²¡í„° ì¶”ì¶œ
        feature_vectors = extract_features(frames)

        # 3ï¸âƒ£ FAISSì— ë²¡í„° ì¶”ê°€
        faiss_index.add_vectors(feature_vectors)
        
        #4ï¸âƒ£ FAISS ì¸ë±ìŠ¤ ì €ì¥(ë²¡í„° ì¶”ê°€ í›„ ìë™ ì €ì¥)
        save_faiss_index()

        return jsonify({"message": "Video processed successfully", "num_frames": len(frames)})

    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route('/faiss_info', methods=['GET'])
def faiss_info():
    """
    í˜„ì¬ FAISSì— ì €ì¥ëœ ë²¡í„° ê°œìˆ˜ë¥¼ í™•ì¸í•˜ëŠ” API
    """
    try:
        load_faiss_index()
        total_vectors = faiss_index.index.ntotal
        print(f"ğŸ“Š í˜„ì¬ ì €ì¥ëœ ë²¡í„° ê°œìˆ˜: {total_vectors}")  # âœ… ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€
        return jsonify({"message": "FAISS index info", "total_vectors": total_vectors})

    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route('/search_similar', methods=['POST'])
def search_similar():
    data = request.json
    video_path = data.get("video_path")  # ê²€ìƒ‰í•  ì˜ìƒ íŒŒì¼ ê²½ë¡œ

    if not video_path or not os.path.exists(video_path):
        return jsonify({"error": "Invalid video path"}), 400

    try:
        # 1ï¸âƒ£ FAISS ì¸ë±ìŠ¤ ë¡œë“œ (í˜¹ì‹œ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì„ ê²½ìš° ëŒ€ë¹„)
        load_faiss_index()
        
        # 1ï¸âƒ£ ì˜ìƒì—ì„œ í”„ë ˆì„ ì¶”ì¶œ
        frames = extract_frames(video_path)

        # 2ï¸âƒ£ í”„ë ˆì„ì—ì„œ íŠ¹ì§• ë²¡í„° ì¶”ì¶œ
        feature_vectors = extract_features(frames)
        
        # FAISSì— ì €ì¥ëœ ë²¡í„° ê°œìˆ˜ í™•ì¸
        total_vectors = faiss_index.index.ntotal
        
        if total_vectors ==0:
            return jsonify({"error":"No vectors stored in FAISS"}), 400

        # 3ï¸âƒ£ FAISSì—ì„œ ìœ ì‚¬í•œ ë²¡í„° ê²€ìƒ‰ (ì²« ë²ˆì§¸ í”„ë ˆì„ ê¸°ì¤€)
        query_vector = feature_vectors[0]
        
        top_k = min(5, total_vectors) #ì €ì¥ëœ ë²¡í„° ê°œìˆ˜ë³´ë‹¤ ë§ì§€ ì•Šê²Œ ì œí•œ
        
        indices, distances = faiss_index.search(query_vector, top_k)


        return jsonify({"message": "Search completed", "indices": indices.tolist(), "distances": distances.tolist()})

    except Exception as e:
        return jsonify({"error": str(e)}), 500

def normalize_faiss_index():
    """FAISSì— ì €ì¥ëœ ë²¡í„°ë¥¼ ì •ê·œí™”í•˜ì—¬ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰ì´ ê°€ëŠ¥í•˜ê²Œ í•¨"""
    total_vectors = faiss_index.index.ntotal
    if total_vectors > 0:
        stored_vectors = np.zeros((total_vectors, 2048), dtype=np.float32)
        for i in range(total_vectors):
            stored_vectors[i] = faiss_index.index.reconstruct(i)
        faiss.normalize_L2(stored_vectors)  # ì •ê·œí™” ìˆ˜í–‰
        faiss_index.index = faiss.IndexFlatIP(2048)  # ë‚´ì ì„ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •
        faiss_index.index.add(stored_vectors)  # ì •ê·œí™”ëœ ë²¡í„° ì¶”ê°€


@app.route('/check_similarity', methods=['POST'])
def check_similarity():
    """
    ì €ì¥ëœ ëª¨ë“  ë²¡í„°ì™€ ì…ë ¥ëœ ì˜ìƒì˜ ë²¡í„° ê°„ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë¹„êµ
    - í•œ ê°œ ì´ìƒì˜ ë²¡í„°ê°€ 0.95 ì´ìƒì´ë©´ì„œ, í‰ê·  ìœ ì‚¬ë„ê°€ 0.8 ì´ìƒì´ë©´ ê°™ì€ ì˜ìƒìœ¼ë¡œ íŒë‹¨
    """
    data = request.json
    video_path = data.get("video_path")  # ë¹„êµí•  ì˜ìƒ íŒŒì¼ ê²½ë¡œ

    if not video_path or not os.path.exists(video_path):
        return jsonify({"error": "Invalid video path"}), 400

    try:
        # 1ï¸âƒ£ FAISS ì¸ë±ìŠ¤ ë¡œë“œ (íŒŒì¼ì´ ìˆë‹¤ë©´ ë¶ˆëŸ¬ì˜¤ê¸°)
        load_faiss_index()

        # 2ï¸âƒ£ ì €ì¥ëœ ë²¡í„° ê°œìˆ˜ í™•ì¸
        total_vectors = faiss_index.index.ntotal
        if total_vectors == 0:
            return jsonify({"message": "ìœ ì‚¬ë„ ê²€ì‚¬ë¥¼ í†µê³¼í•˜ì˜€ìŠµë‹ˆë‹¤"}), 200

        # 3ï¸âƒ£ ë¹„êµí•  ì˜ìƒì—ì„œ í”„ë ˆì„ ì¶”ì¶œ
        frames = extract_frames(video_path)

        # 4ï¸âƒ£ í”„ë ˆì„ì˜ íŠ¹ì§• ë²¡í„° ì¶”ì¶œ
        feature_vectors = extract_features(frames)

        # 5ï¸âƒ£ ë²¡í„° ì •ê·œí™” (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ë¹„êµ)
        query_vectors = np.array(feature_vectors).astype('float32')
        faiss.normalize_L2(query_vectors)

        # 6ï¸âƒ£ ê° í”„ë ˆì„ì˜ ë²¡í„°ë¥¼ FAISSì— ì €ì¥ëœ ëª¨ë“  ë²¡í„°ì™€ ë¹„êµ
        similarity_scores = []
        for query_vector in query_vectors:
            query_vector = query_vector.reshape(1, -1)
            
            faiss.normalize_L2(query_vector) # âœ… ê²€ìƒ‰ ë²¡í„° ì •ê·œí™”
            # FAISSì—ì„œ ì €ì¥ëœ ëª¨ë“  ë²¡í„°ì™€ ìœ ì‚¬ë„ ê²€ì‚¬
            distances, _ = faiss_index.index.search(query_vector, total_vectors)

            # FAISSëŠ” ë‚´ì ì„ ë°˜í™˜í•˜ë¯€ë¡œ, ê°’ì´ í´ìˆ˜ë¡ ìœ ì‚¬í•œ ê²ƒ (1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬)í•¨
            similarity_scores.extend(distances[0].tolist())

        # 7ï¸âƒ£ ê²€ì‚¬ ê¸°ì¤€ ì ìš©
        max_similarity = max(similarity_scores)  # ê°€ì¥ ë†’ì€ ìœ ì‚¬ë„
        avg_similarity = sum(similarity_scores) / len(similarity_scores)  # í‰ê·  ìœ ì‚¬ë„

        if max_similarity >= 0.9 and avg_similarity >= 0.8:
            return jsonify({
                "message": "ê°™ì€ ì˜ìƒì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤",
                "max_similarity": max_similarity,
                "avg_similarity": avg_similarity
            }), 200
        else:
            return jsonify({
                "message": "ìœ ì‚¬ë„ ê²€ì‚¬ë¥¼ í†µê³¼í•˜ì˜€ìŠµë‹ˆë‹¤",
                "max_similarity": max_similarity,
                "avg_similarity": avg_similarity
            }), 200

    except Exception as e:
        return jsonify({"error": str(e)}), 500




if __name__ == '__main__':
    app.run(debug=True)